services:
  # AI Observer as sidecar
  observer:
    build: .
    container_name: axom-observer
    ports:
      - "8888:8888"   # HTTP proxy
      - "8443:8443"   # HTTPS proxy
    environment:
      - CUSTOMER_ID=${CUSTOMER_ID}
      - AGENT_ID=${AGENT_ID}
      - CLIENT_ID=${CLIENT_ID}
      - CLIENT_SECRET=${CLIENT_SECRET}
      - BACKEND_URL=${BACKEND_URL:-https://api.axom.ai/ingest}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - LOG_ALL_TRAFFIC=${LOG_ALL_TRAFFIC:-true}
      - MAIN_AI_CONTAINER_NAME=${MAIN_AI_CONTAINER_NAME:-my-ai-app}
      - OBSERVER_DASHBOARD_USER=${OBSERVER_DASHBOARD_USER:-}
      - OBSERVER_DASHBOARD_PASS=${OBSERVER_DASHBOARD_PASS:-}
    volumes:
      - ./certs:/app/certs:ro  # Mount certificates if needed
      - observer-logs:/app/logs
    networks:
      - observer-network
    restart: unless-stopped

  # Demo AI app for testing
  demo-ai-app:
    build:
      context: ./demo
      dockerfile: Dockerfile
    container_name: demo-ai-app
    ports:
      - "5002:5002"
    environment:
      - FLASK_ENV=development
    networks:
      - observer-network
    restart: unless-stopped
    depends_on:
      - observer

  # Backend service for receiving signals
  backend:
    image: nginx:alpine
    container_name: signal-backend
    ports:
      - "8080:80"
    volumes:
      - ./backend/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./backend/html:/usr/share/nginx/html:ro
    networks:
      - observer-network
    restart: unless-stopped

volumes:
  observer-logs:

networks:
  observer-network:
    driver: bridge